input {
  file {
    path            => "/usr/share/logstash/ingest_data/*"
    mode            => "read"           # lit tout le fichier une seule fois
    start_position  => "beginning"      # commence au tout début
    sincedb_path    => "/dev/null"      # oublie l’offset à chaque démarrage
  }
}


filter {
  csv {
    separator    => ","
    skip_header  => "true"
    columns      => [
      "unique_id","indicator_id","name","measure","measure_info",
      "geo_type","geo_join_id","geo_place","time_period",
      "start_date","data_value","message"
    ]
  }

  date {                       # transforme Start_Date -> @timestamp
    match        => ["start_date","MM/dd/yyyy"]
    target       => "@timestamp"
    timezone     => "America/New_York"
    remove_field => ["start_date"]
  }

  mutate {                     # convertit la valeur numérique
    convert => { "data_value" => "float" }
  }
}

output {
 elasticsearch {
   index => "logstash-%{+YYYY.MM.dd}"
   hosts=> "${ELASTIC_HOSTS}"
   user=> "${ELASTIC_USER}"
   password=> "${ELASTIC_PASSWORD}"
   cacert=> "certs/ca/ca.crt"
 }
}
